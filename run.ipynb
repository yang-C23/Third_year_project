{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23081,
     "status": "ok",
     "timestamp": 1687613399436,
     "user": {
      "displayName": "崔洋",
      "userId": "11100323723687542220"
     },
     "user_tz": -480
    },
    "id": "8XoAJo4Gl8Sl",
    "outputId": "46a82a7b-05b3-4a5a-cee3-7539c65afbcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1687613430764,
     "user": {
      "displayName": "崔洋",
      "userId": "11100323723687542220"
     },
     "user_tz": -480
    },
    "id": "O1qcPueLmGVn",
    "outputId": "df818b0f-7c88-4b8f-b63d-f1994b0122ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/3rd_year_project/MedTem\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/.../MedTem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42745,
     "status": "ok",
     "timestamp": 1687613510712,
     "user": {
      "displayName": "崔洋",
      "userId": "11100323723687542220"
     },
     "user_tz": -480
    },
    "id": "I5x4_dW6mGTU",
    "outputId": "3ed9aec7-4f8b-46e6-e6a4-3e59e5e659e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting openprompt\n",
      "  Downloading openprompt-1.0.1-py3-none-any.whl (146 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.4/146.4 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting transformers>=4.10.0 (from openprompt)\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.2/7.2 MB\u001B[0m \u001B[31m64.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting sentencepiece==0.1.96 (from openprompt)\n",
      "  Downloading sentencepiece-0.1.96-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m53.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.62.2 in /usr/local/lib/python3.10/dist-packages (from openprompt) (4.65.0)\n",
      "Collecting tensorboardX (from openprompt)\n",
      "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.6/101.6 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from openprompt) (3.8.1)\n",
      "Collecting yacs (from openprompt)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting dill (from openprompt)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m110.5/110.5 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting datasets (from openprompt)\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m486.2/486.2 kB\u001B[0m \u001B[31m45.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting rouge==1.0.0 (from openprompt)\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openprompt) (9.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from openprompt) (1.10.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge==1.0.0->openprompt) (1.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.10.0->openprompt)\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m236.8/236.8 kB\u001B[0m \u001B[31m24.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->openprompt) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.10.0->openprompt)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m98.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting safetensors>=0.3.1 (from transformers>=4.10.0->openprompt)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m71.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->openprompt) (1.5.3)\n",
      "Collecting xxhash (from datasets->openprompt)\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m212.5/212.5 kB\u001B[0m \u001B[31m21.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting multiprocess (from datasets->openprompt)\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.3/134.3 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->openprompt) (2023.6.0)\n",
      "Collecting aiohttp (from datasets->openprompt)\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m66.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->openprompt) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->openprompt) (1.2.0)\n",
      "Collecting protobuf>=4.22.3 (from tensorboardX->openprompt)\n",
      "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m304.5/304.5 kB\u001B[0m \u001B[31m28.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->openprompt) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->openprompt) (2.0.12)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->openprompt)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.5/114.5 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->openprompt)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->openprompt)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m268.8/268.8 kB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->openprompt)\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m149.6/149.6 kB\u001B[0m \u001B[31m14.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->openprompt)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.10.0->openprompt) (4.6.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->openprompt) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->openprompt) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->openprompt) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openprompt) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->openprompt) (2022.7.1)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, yacs, xxhash, rouge, protobuf, multidict, frozenlist, dill, async-timeout, yarl, tensorboardX, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, openprompt\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.13.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 openprompt-1.0.1 protobuf-4.23.3 rouge-1.0.0 safetensors-0.3.1 sentencepiece-0.1.96 tensorboardX-2.6.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0 yacs-0.1.8 yarl-1.9.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install openprompt\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCXWZvlpmfnp",
    "outputId": "5b32e98d-71d4-4d77-cef2-05273529197e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "2023-06-24 13:33:17.106682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "train_label_ON_dataset 5\n",
      "train_label_OFF_dataset 5\n",
      "10\n",
      "{\n",
      "  \"guid\": 9,\n",
      "  \"label\": 0,\n",
      "  \"meta\": \"121.xml.tlink\",\n",
      "  \"text_a\": \"ADMISSION DATE : 09-07-93 DISCHARGE DATE : 09-08-93 PATIENT DIED ON 9/8/93 . . Dorctor notes: Electrolytes at this time were a sodium of 148 , potassium 1.7 . At 9/7/93 , 1:00 a.m. , intravenous fluids rate was decreased to 50 cc&apos;s per hour , total fluids given during the first 24 hours were 140 to 150 cc&apos;s per kilo per day . At this time , sodium was 147 , potassium 2.6 , total sodium given during the first 24 hours 20 mEq per kilo per day . On 9/7/93 at 4:00 a.m. , albumin bolus 5% 10 cc&apos;s per kilo was given , a total of 120 cc&apos;s , electrolytes were sodium 155 , potassium 3.1 . At 9/7/93 at 5:00 a.m. , sodium bicarbonate given 60 mEq , calcium bolus 10 cc&apos;s given . On 9/7 , 5:30 a.m. , D5 quarter normal saline , and 40 of K phosphate at 100 cc&apos;s per hour was given . \",\n",
      "  \"text_b\": \"albumin bolus\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n",
      "number of ON train 5\n",
      "number of OFF train 5\n",
      "total number of training set 10\n",
      "number of ON test 3164\n",
      "number of OFF test 921\n",
      "Downloading (…)lve/main/config.json: 1.21kB [00:00, 3.31MB/s]\n",
      "Downloading model.safetensors: 100% 892M/892M [00:09<00:00, 93.4MB/s]\n",
      "Downloading (…)neration_config.json: 100% 147/147 [00:00<00:00, 843kB/s]\n",
      "Downloading (…)ve/main/spiece.model: 100% 792k/792k [00:00<00:00, 7.04MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "tokenizing: 10it [00:00, 465.51it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/pbl.py\", line 193, in <module>\n",
      "    pbl_train_and_evaluate(train_dataset_prompt = train_dataset_prompt, validation_dataloader_prompt = test_dataset_prompt, plm=plm , mytemplate = mytemplate, myverbalizer = myverbalizer, tokenizer = tokenizer, WrapperClass = WrapperClass)\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/pbl.py\", line 94, in pbl_train_and_evaluate\n",
      "    prompt_model = prompt_model.cuda()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in cuda\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in <lambda>\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "!python pbl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40571,
     "status": "ok",
     "timestamp": 1687613588736,
     "user": {
      "displayName": "崔洋",
      "userId": "11100323723687542220"
     },
     "user_tz": -480
    },
    "id": "HMjxHrZGmnWJ",
    "outputId": "02a011de-74e0-432f-d677-23cba032192d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-24 13:32:36.376246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "train_label_ON_dataset 5\n",
      "train_label_OFF_dataset 5\n",
      "10\n",
      "{\n",
      "  \"guid\": 9,\n",
      "  \"label\": 0,\n",
      "  \"meta\": \"797.xml.tlink\",\n",
      "  \"text_a\": \"Admission Date : 2012-11-06 Discharge Date : 2012-11-11 . Dorctor notes: The patient presented to Bournewood Hospital on the morning of admission with a chief complaint of substernal burning without radiation which developed while doing exercise . Of note , this is the second time the patient has exercised in many months . The pain became worse over the next few minutes to 07-12 and increased to 10-12 while he was in the ambulance . His nitroglycerin patch did not help , and he only had slight relief with sublingual nitroglycerin times three . In addition , he had slight shortness of breath but denies headache , change in vision , dizziness , nausea , vomiting , abdominal pain , change in bowel or urinary habits , or fevers , chills , and sweats . Of note , he had a negative stress test in 2012-07-03 . \",\n",
      "  \"text_b\": \"sublingual nitroglycerin\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n",
      "number of ON train 5\n",
      "number of OFF train 5\n",
      "total number of training set 10\n",
      "number of ON test 3164\n",
      "number of OFF test 921\n",
      "Downloading (…)solve/main/vocab.txt: 232kB [00:00, 4.69MB/s]\n",
      "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 162kB/s]\n",
      "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.29MB/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "    9 training samples\n",
      "    1 validation samples\n",
      "Downloading model.safetensors: 100% 440M/440M [00:03<00:00, 129MB/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/fine_tuning.py\", line 421, in <module>\n",
      "    fine_tuning_train_and_evaluate(train_dataset_tuning=train_dataset_tuning, test_dataset_tuning=test_dataset_tuning)\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/fine_tuning.py\", line 107, in fine_tuning_train_and_evaluate\n",
      "    model.cuda()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in cuda\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in <lambda>\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "!python fine_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D3sRRzQRmvVf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "2023-06-24 13:33:41.391495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "train_label_ON_dataset 5\n",
      "train_label_OFF_dataset 5\n",
      "10\n",
      "{\n",
      "  \"guid\": 9,\n",
      "  \"label\": 0,\n",
      "  \"meta\": \"121.xml.tlink\",\n",
      "  \"text_a\": \"ADMISSION DATE : 09-07-93 DISCHARGE DATE : 09-08-93 PATIENT DIED ON 9/8/93 . . Dorctor notes: Cardiovascular stable , significant hypertension was noted on 9/7/93 at 5:10 a.m. and therefore 10 cc&apos;s per kilo albumin was given . The patient was admitted was started on clear fluids , tolerated , with D5 normal saline plus 40 mEq per liter of KCL at a rate of 50 cc &apos;s per hour for 9 hours . ( 100 cc&apos;s per kilo ) . Sodium and potassium at this time were 128/1.5 . At Labor Day , 9:30 a.m. , the fluids were increased to 100 cc&apos;s per hour ( 200 cc&apos;s per kilo for 5 hours ) . Electrolytes at this point were sodium 132 , potassium 1.8 . At 9/6/93 , 2:30 p.m. , fluids were decreased to 75 cc&apos;s per hour , 150 cc&apos;s per kilo , 40 mEq of K phosphate added to the intravenous fluids . \",\n",
      "  \"text_b\": \"the fluids\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n",
      "number of ON train 5\n",
      "number of OFF train 5\n",
      "total number of training set 10\n",
      "number of ON test 3164\n",
      "number of OFF test 921\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizing: 10it [00:00, 223.82it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/main.py\", line 36, in <module>\n",
      "    pbl_train_and_evaluate(train_dataset_prompt=train_dataset_prompt, validation_dataloader_prompt=test_dataset_prompt,\n",
      "  File \"/content/drive/MyDrive/3rd_year_project/MedTem/pbl.py\", line 94, in pbl_train_and_evaluate\n",
      "    prompt_model = prompt_model.cuda()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in cuda\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 905, in <lambda>\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNA/7owXgKVrH90ydSz14p",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}